{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dimensionality reduction and Visualization     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>RMS</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Crest Factor</th>\n",
       "      <th>Form Factor</th>\n",
       "      <th>Fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.117085</td>\n",
       "      <td>0.093069</td>\n",
       "      <td>0.149567</td>\n",
       "      <td>-0.012753</td>\n",
       "      <td>0.931376</td>\n",
       "      <td>2.661008</td>\n",
       "      <td>-1.277421</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.117744</td>\n",
       "      <td>0.093095</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>-0.033307</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>2.811460</td>\n",
       "      <td>-1.274798</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>-0.116695</td>\n",
       "      <td>0.091405</td>\n",
       "      <td>0.148230</td>\n",
       "      <td>0.022064</td>\n",
       "      <td>0.946745</td>\n",
       "      <td>3.143757</td>\n",
       "      <td>-1.270240</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.117174</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.150430</td>\n",
       "      <td>-0.088984</td>\n",
       "      <td>0.858388</td>\n",
       "      <td>2.366546</td>\n",
       "      <td>-1.283821</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.647</td>\n",
       "      <td>-0.117876</td>\n",
       "      <td>0.093033</td>\n",
       "      <td>0.150165</td>\n",
       "      <td>-0.036459</td>\n",
       "      <td>0.957214</td>\n",
       "      <td>3.329671</td>\n",
       "      <td>-1.273921</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>0.701</td>\n",
       "      <td>-0.764</td>\n",
       "      <td>-0.114628</td>\n",
       "      <td>0.131560</td>\n",
       "      <td>0.174490</td>\n",
       "      <td>0.134774</td>\n",
       "      <td>1.459441</td>\n",
       "      <td>4.017426</td>\n",
       "      <td>-1.522231</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>-0.114702</td>\n",
       "      <td>0.126378</td>\n",
       "      <td>0.170667</td>\n",
       "      <td>0.071571</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>3.345699</td>\n",
       "      <td>-1.487915</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>0.623</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>-0.114239</td>\n",
       "      <td>0.126722</td>\n",
       "      <td>0.170611</td>\n",
       "      <td>0.100394</td>\n",
       "      <td>1.255684</td>\n",
       "      <td>3.651572</td>\n",
       "      <td>-1.493457</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>0.752</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-0.114455</td>\n",
       "      <td>0.128396</td>\n",
       "      <td>0.172002</td>\n",
       "      <td>0.086076</td>\n",
       "      <td>1.189483</td>\n",
       "      <td>4.372047</td>\n",
       "      <td>-1.502786</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>0.583</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.114645</td>\n",
       "      <td>0.123409</td>\n",
       "      <td>0.168441</td>\n",
       "      <td>0.106775</td>\n",
       "      <td>1.241986</td>\n",
       "      <td>3.461146</td>\n",
       "      <td>-1.469247</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Max    Min      Mean       Std       RMS  Skewness  Kurtosis  \\\n",
       "0     0.398 -0.625 -0.117085  0.093069  0.149567 -0.012753  0.931376   \n",
       "1     0.422 -0.657 -0.117744  0.093095  0.150100 -0.033307  0.876667   \n",
       "2     0.466 -0.605 -0.116695  0.091405  0.148230  0.022064  0.946745   \n",
       "3     0.356 -0.713 -0.117174  0.094340  0.150430 -0.088984  0.858388   \n",
       "4     0.500 -0.647 -0.117876  0.093033  0.150165 -0.036459  0.957214   \n",
       "...     ...    ...       ...       ...       ...       ...       ...   \n",
       "2273  0.701 -0.764 -0.114628  0.131560  0.174490  0.134774  1.459441   \n",
       "2274  0.571 -0.667 -0.114702  0.126378  0.170667  0.071571  1.195710   \n",
       "2275  0.623 -0.708 -0.114239  0.126722  0.170611  0.100394  1.255684   \n",
       "2276  0.752 -0.686 -0.114455  0.128396  0.172002  0.086076  1.189483   \n",
       "2277  0.583 -0.737 -0.114645  0.123409  0.168441  0.106775  1.241986   \n",
       "\n",
       "      Crest Factor  Form Factor           Fault  \n",
       "0         2.661008    -1.277421          Normal  \n",
       "1         2.811460    -1.274798          Normal  \n",
       "2         3.143757    -1.270240          Normal  \n",
       "3         2.366546    -1.283821          Normal  \n",
       "4         3.329671    -1.273921          Normal  \n",
       "...            ...          ...             ...  \n",
       "2273      4.017426    -1.522231  Roller Element  \n",
       "2274      3.345699    -1.487915  Roller Element  \n",
       "2275      3.651572    -1.493457  Roller Element  \n",
       "2276      4.372047    -1.502786  Roller Element  \n",
       "2277      3.461146    -1.469247  Roller Element  \n",
       "\n",
       "[2278 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('Normal_Bearing.csv')\n",
    "df2=pd.read_csv('outer_race_fault_test_2.csv')\n",
    "df3=pd.read_csv('outer_race_fault_test_3.csv')\n",
    "df4=pd.read_csv('inner_race_fault.csv')\n",
    "df5=pd.read_csv('roller_element_fault.csv')\n",
    "\n",
    "df = pd.concat([df1,df2,df3,df4,df5])\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with TWO Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca_2 = PCA(n_components=2)\n",
    "X_pca = pca_2.fit_transform(X)\n",
    "\n",
    "principalDf = pd.DataFrame(data = X_pca, columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "principalDf['Fault']=np.array(df['Fault'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>Fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.579635</td>\n",
       "      <td>0.169355</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.497286</td>\n",
       "      <td>0.161143</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.512591</td>\n",
       "      <td>-0.003158</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532749</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.355692</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>-0.334664</td>\n",
       "      <td>0.321128</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>-0.022995</td>\n",
       "      <td>0.465198</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>-0.123749</td>\n",
       "      <td>0.366848</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>-0.349936</td>\n",
       "      <td>0.247044</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>-0.041109</td>\n",
       "      <td>0.349603</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      principal component 1  principal component 2           Fault\n",
       "0                  0.579635               0.169355          Normal\n",
       "1                  0.497286               0.161143          Normal\n",
       "2                  0.512591              -0.003158          Normal\n",
       "3                  0.532749               0.334986          Normal\n",
       "4                  0.355692               0.043308          Normal\n",
       "...                     ...                    ...             ...\n",
       "2273              -0.334664               0.321128  Roller Element\n",
       "2274              -0.022995               0.465198  Roller Element\n",
       "2275              -0.123749               0.366848  Roller Element\n",
       "2276              -0.349936               0.247044  Roller Element\n",
       "2277              -0.041109               0.349603  Roller Element\n",
       "\n",
       "[2278 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal', 'Outer Race', 'Inner Race', 'Roller Element'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf['Fault'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25f42c5cec0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "fault = ['Normal', 'Outer Race', 'Inner Race', 'Roller Element']\n",
    "colors = ['g', 'r','b','y']\n",
    "for fault, color in zip(fault,colors):\n",
    "    indicesToKeep = principalDf['Fault'] == fault\n",
    "    ax.scatter(principalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , principalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(['Normal', 'Outer Race', 'Inner Race', 'Roller Element'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47682508, 0.18028137])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca_2.explained_variance_ratio_)\n",
    "pca_2.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with THREE Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca_3 = PCA(n_components=3)\n",
    "\n",
    "X_pca = pca_3.fit_transform(X)\n",
    "\n",
    "principalDf = pd.DataFrame(data = X_pca, columns = ['principal component 1', 'principal component 2','principal component 3'])\n",
    "\n",
    "principalDf['Fault']=np.array(df['Fault'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>principal component 3</th>\n",
       "      <th>Fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.579635</td>\n",
       "      <td>0.169355</td>\n",
       "      <td>1.566971</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.497286</td>\n",
       "      <td>0.161143</td>\n",
       "      <td>1.545753</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.512591</td>\n",
       "      <td>-0.003158</td>\n",
       "      <td>1.437180</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532749</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>1.659122</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.355692</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>1.421535</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>-0.334664</td>\n",
       "      <td>0.321128</td>\n",
       "      <td>1.191084</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>-0.022995</td>\n",
       "      <td>0.465198</td>\n",
       "      <td>1.374193</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>-0.123749</td>\n",
       "      <td>0.366848</td>\n",
       "      <td>1.285651</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>-0.349936</td>\n",
       "      <td>0.247044</td>\n",
       "      <td>1.115621</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>-0.041109</td>\n",
       "      <td>0.349603</td>\n",
       "      <td>1.334219</td>\n",
       "      <td>Roller Element</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      principal component 1  principal component 2  principal component 3  \\\n",
       "0                  0.579635               0.169355               1.566971   \n",
       "1                  0.497286               0.161143               1.545753   \n",
       "2                  0.512591              -0.003158               1.437180   \n",
       "3                  0.532749               0.334986               1.659122   \n",
       "4                  0.355692               0.043308               1.421535   \n",
       "...                     ...                    ...                    ...   \n",
       "2273              -0.334664               0.321128               1.191084   \n",
       "2274              -0.022995               0.465198               1.374193   \n",
       "2275              -0.123749               0.366848               1.285651   \n",
       "2276              -0.349936               0.247044               1.115621   \n",
       "2277              -0.041109               0.349603               1.334219   \n",
       "\n",
       "               Fault  \n",
       "0             Normal  \n",
       "1             Normal  \n",
       "2             Normal  \n",
       "3             Normal  \n",
       "4             Normal  \n",
       "...              ...  \n",
       "2273  Roller Element  \n",
       "2274  Roller Element  \n",
       "2275  Roller Element  \n",
       "2276  Roller Element  \n",
       "2277  Roller Element  \n",
       "\n",
       "[2278 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyQt5 in d:\\bearing_fault_ diagnosis\\venv\\lib\\site-packages (5.15.11)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.15 in d:\\bearing_fault_ diagnosis\\venv\\lib\\site-packages (from PyQt5) (12.17.0)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in d:\\bearing_fault_ diagnosis\\venv\\lib\\site-packages (from PyQt5) (5.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyQt5\n",
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(figsize=(10,14))\n",
    "  \n",
    "# syntax for 3-D projection\n",
    "ax = plt.axes(projection='3d')\n",
    "  \n",
    "# defining all 3 axes\n",
    "fault = ['Normal', 'Outer Race', 'Inner Race', 'Roller Element']\n",
    "colors = ['g', 'r','b','y']\n",
    "for fault, color in zip(fault,colors):\n",
    "    indicesToKeep = principalDf['Fault'] == fault\n",
    "    ax.scatter3D(principalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , principalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , principalDf.loc[indicesToKeep, 'principal component 3']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(['Normal', 'Outer Race', 'Inner Race', 'Roller Element'])\n",
    "\n",
    "  \n",
    "# plotting\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_zlabel('Principal Component 3', fontsize = 15)\n",
    "\n",
    "ax.set_title('3D PCA')\n",
    "ax.view_init(45,90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8029781707108328)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca_3.explained_variance_ratio_)\n",
    "#pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with FOUR Principal Components\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca_4 = PCA(n_components=4)\n",
    "X_pca = pca_4.fit_transform(X)\n",
    "\n",
    "principalDf = pd.DataFrame(\n",
    "    data = X_pca, \n",
    "    columns = ['principal component 1', 'principal component 2',\n",
    "               'principal component 3', 'principal component 4']\n",
    ")\n",
    "\n",
    "principalDf['Fault'] = np.array(df['Fault'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explained variance: 0.9338\n",
      "Individual component explained variance:\n",
      "PC1: 0.4768\n",
      "PC2: 0.1803\n",
      "PC3: 0.1459\n",
      "PC4: 0.1309\n"
     ]
    }
   ],
   "source": [
    "# Show explained variance for 4 components\n",
    "print(f\"Total explained variance: {np.sum(pca_4.explained_variance_ratio_):.4f}\")\n",
    "print(\"Individual component explained variance:\")\n",
    "for i, var in enumerate(pca_4.explained_variance_ratio_):\n",
    "    print(f\"PC{i+1}: {var:.4f}\")\n",
    "\n",
    "# Create pairwise scatter plots between the components\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a pair plot to visualize relationships between components\n",
    "plt.figure(figsize=(12, 10))\n",
    "fault_types = ['Normal', 'Outer Race', 'Inner Race', 'Roller Element']\n",
    "fault_colors = {'Normal': 'g', 'Outer Race': 'r', 'Inner Race': 'b', 'Roller Element': 'y'}\n",
    "\n",
    "# Create pairplot with Seaborn\n",
    "sns.pairplot(principalDf, hue='Fault', palette=fault_colors, \n",
    "             vars=principalDf.columns[:4], height=2.5)\n",
    "plt.suptitle('Pairwise Relationships Between Principal Components', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explained variance: 0.9776\n",
      "Individual component explained variance:\n",
      "PC1: 0.4768\n",
      "PC2: 0.1803\n",
      "PC3: 0.1459\n",
      "PC4: 0.1309\n",
      "PC5: 0.0438\n"
     ]
    }
   ],
   "source": [
    "# PCA with FIVE Principal Components\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca_5 = PCA(n_components=5)\n",
    "X_pca = pca_5.fit_transform(X)\n",
    "\n",
    "principalDf = pd.DataFrame(\n",
    "    data = X_pca, \n",
    "    columns = ['principal component 1', 'principal component 2',\n",
    "               'principal component 3', 'principal component 4',\n",
    "               'principal component 5']\n",
    ")\n",
    "\n",
    "principalDf['Fault'] = np.array(df['Fault'])\n",
    "\n",
    "# Show explained variance for 5 components\n",
    "print(f\"Total explained variance: {np.sum(pca_5.explained_variance_ratio_):.4f}\")\n",
    "print(\"Individual component explained variance:\")\n",
    "for i, var in enumerate(pca_5.explained_variance_ratio_):\n",
    "    print(f\"PC{i+1}: {var:.4f}\")\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "cumulative_variance = np.cumsum(pca_5.explained_variance_ratio_)\n",
    "plt.bar(range(1, 6), pca_5.explained_variance_ratio_, alpha=0.6, color='b', label='Individual explained variance')\n",
    "plt.step(range(1, 6), cumulative_variance, where='mid', label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.show()\n",
    "\n",
    "# Visualize with pairplot for first 3 components (can't easily view all 5D)\n",
    "import seaborn as sns\n",
    "fault_colors = {'Normal': 'g', 'Outer Race': 'r', 'Inner Race': 'b', 'Roller Element': 'y'}\n",
    "sns.pairplot(principalDf, \n",
    "             vars=principalDf.columns[:3],  # Just show first 3 for clarity\n",
    "             hue='Fault', \n",
    "             palette=fault_colors,\n",
    "             height=2.5)\n",
    "plt.suptitle('First 3 of 5 Principal Components', y=1.02, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "sns.pairplot(principalDf, \n",
    "             vars=principalDf.columns[:5],  # Use all 5 components\n",
    "             hue='Fault', \n",
    "             palette=fault_colors,\n",
    "             height=2.0)  # Smaller subplot size to fit all\n",
    "plt.suptitle('All 5 Principal Components', y=1.02, fontsize=16)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with SIX Principal Components\n",
    "Let's extend our analysis to six principal components to see if we can capture even more variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explained variance: 0.9915\n",
      "Individual component explained variance:\n",
      "PC1: 0.4768\n",
      "PC2: 0.1803\n",
      "PC3: 0.1459\n",
      "PC4: 0.1309\n",
      "PC5: 0.0438\n",
      "PC6: 0.0139\n"
     ]
    }
   ],
   "source": [
    "# PCA with SIX Principal Components\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca_6 = PCA(n_components=6)\n",
    "X_pca = pca_6.fit_transform(X)\n",
    "\n",
    "principalDf = pd.DataFrame(\n",
    "    data = X_pca, \n",
    "    columns = ['principal component 1', 'principal component 2',\n",
    "               'principal component 3', 'principal component 4',\n",
    "               'principal component 5', 'principal component 6']\n",
    ")\n",
    "\n",
    "principalDf['Fault'] = np.array(df['Fault'])\n",
    "\n",
    "# Show explained variance for 6 components\n",
    "print(f\"Total explained variance: {np.sum(pca_6.explained_variance_ratio_):.4f}\")\n",
    "print(\"Individual component explained variance:\")\n",
    "for i, var in enumerate(pca_6.explained_variance_ratio_):\n",
    "    print(f\"PC{i+1}: {var:.4f}\")\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "cumulative_variance = np.cumsum(pca_6.explained_variance_ratio_)\n",
    "plt.bar(range(1, 7), pca_6.explained_variance_ratio_, alpha=0.6, color='b', label='Individual explained variance')\n",
    "plt.step(range(1, 7), cumulative_variance, where='mid', label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.xticks(range(1, 7))\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most influential features for each principal component:\n",
      "\n",
      "PC1:\n",
      "  Min: 0.4581\n",
      "  Max: -0.4439\n",
      "  Kurtosis: -0.3855\n",
      "\n",
      "PC2:\n",
      "  Std: 0.5362\n",
      "  Form Factor: -0.4620\n",
      "  Crest Factor: -0.4223\n",
      "\n",
      "PC3:\n",
      "  Form Factor: 0.6014\n",
      "  Mean: -0.5897\n",
      "  Crest Factor: -0.4122\n",
      "\n",
      "PC4:\n",
      "  Skewness: 0.8346\n",
      "  Kurtosis: -0.3024\n",
      "  Max: 0.2255\n",
      "\n",
      "PC5:\n",
      "  Form Factor: 0.6450\n",
      "  Mean: 0.6001\n",
      "  Std: 0.4008\n",
      "\n",
      "PC6:\n",
      "  Kurtosis: 0.7693\n",
      "  Crest Factor: -0.3852\n",
      "  Skewness: 0.3616\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature loadings (component coefficients) for 6 PCs\n",
    "loadings = pca_6.components_\n",
    "feature_names = df.drop('Fault', axis=1).columns\n",
    "\n",
    "# Create a heatmap of feature loadings\n",
    "plt.figure(figsize=(12, 8))\n",
    "loadings_df = pd.DataFrame(\n",
    "    loadings, \n",
    "    columns=feature_names,\n",
    "    index=[f'PC{i+1}' for i in range(6)]\n",
    ")\n",
    "sns.heatmap(loadings_df, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('PCA Feature Loadings (6 Components)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the most influential features for each principal component\n",
    "print(\"Most influential features for each principal component:\")\n",
    "for i, pc in enumerate(loadings):\n",
    "    sorted_indices = np.argsort(np.abs(pc))[::-1]\n",
    "    print(f\"\\nPC{i+1}:\")\n",
    "    for idx in sorted_indices[:3]:  # Top 3 features\n",
    "        print(f\"  {feature_names[idx]}: {pc[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the pairs of first few principal components\n",
    "# Create a subset of the data with colors by fault type\n",
    "import seaborn as sns\n",
    "fault_colors = {'Normal': 'g', 'Outer Race': 'r', 'Inner Race': 'b', 'Roller Element': 'y'}\n",
    "\n",
    "# Create pairplot for the first 3 components (for better visualization)\n",
    "pca_pairs = sns.pairplot(principalDf, \n",
    "                         vars=principalDf.columns[:3],  # First 3 components\n",
    "                         hue='Fault', \n",
    "                         palette=fault_colors,\n",
    "                         height=2.5)\n",
    "plt.suptitle('First 3 of 6 Principal Components', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for model training\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Let's use the dataset with 6 principal components\n",
    "X = principalDf.drop('Fault', axis=1).values\n",
    "y = principalDf['Fault'].values\n",
    "\n",
    "# Convert categorical labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split dataset into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # normalize so that max value is 1\n",
    "    cm = cm.astype(float) / cm.max()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to evaluate and display metrics\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n--- {model_name} Model Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Add metrics to results dictionary for comparison\n",
    "    model_results[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    plot_confusion_matrix(y_true, y_pred, model_name)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Dictionary to store results for comparison\n",
    "model_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models with Reduced Features\n",
    "\n",
    "In this section, we'll implement and compare multiple machine learning models using our reduced features from PCA. We'll evaluate:\n",
    "\n",
    "1. 1D Convolutional Neural Network (1DCNN)\n",
    "2. Long Short-Term Memory (LSTM)\n",
    "3. Random Forest (RF)\n",
    "4. Support Vector Machine (SVM)\n",
    "\n",
    "For each model, we'll display:\n",
    "- Confusion matrix\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest (RF) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Model Evaluation ---\n",
      "Accuracy: 0.9605\n",
      "Precision: 0.9609\n",
      "Recall: 0.9605\n",
      "F1-score: 0.9606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "rf_metrics = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "\n",
    "# Feature importance for RF model\n",
    "feature_importance = rf_model.feature_importances_\n",
    "pc_names = [f'PC{i+1}' for i in range(X.shape[1])]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "plt.barh(np.array(pc_names)[sorted_idx], feature_importance[sorted_idx])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Random Forest - Feature Importance of Principal Components\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machine (SVM) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM Model Evaluation ---\n",
      "Accuracy: 0.9503\n",
      "Precision: 0.9515\n",
      "Recall: 0.9503\n",
      "F1-score: 0.9504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "svm_metrics = evaluate_model(y_test, y_pred_svm, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 1D Convolutional Neural Network (1DCNN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.1834, Val Loss: 0.9196, Train Acc: 0.4612, Val Acc: 0.5423\n",
      "Epoch [2/50], Train Loss: 0.7923, Val Loss: 0.6241, Train Acc: 0.6196, Val Acc: 0.7994\n",
      "Epoch [3/50], Train Loss: 0.5984, Val Loss: 0.4811, Train Acc: 0.7341, Val Acc: 0.7743\n",
      "Epoch [4/50], Train Loss: 0.5119, Val Loss: 0.4232, Train Acc: 0.7600, Val Acc: 0.8433\n",
      "Epoch [3/50], Train Loss: 0.5984, Val Loss: 0.4811, Train Acc: 0.7341, Val Acc: 0.7743\n",
      "Epoch [4/50], Train Loss: 0.5119, Val Loss: 0.4232, Train Acc: 0.7600, Val Acc: 0.8433\n",
      "Epoch [5/50], Train Loss: 0.4416, Val Loss: 0.3664, Train Acc: 0.8000, Val Acc: 0.8746\n",
      "Epoch [6/50], Train Loss: 0.4055, Val Loss: 0.3586, Train Acc: 0.8165, Val Acc: 0.8464\n",
      "Epoch [5/50], Train Loss: 0.4416, Val Loss: 0.3664, Train Acc: 0.8000, Val Acc: 0.8746\n",
      "Epoch [6/50], Train Loss: 0.4055, Val Loss: 0.3586, Train Acc: 0.8165, Val Acc: 0.8464\n",
      "Epoch [7/50], Train Loss: 0.3599, Val Loss: 0.3159, Train Acc: 0.8416, Val Acc: 0.8840\n",
      "Epoch [8/50], Train Loss: 0.3490, Val Loss: 0.3098, Train Acc: 0.8431, Val Acc: 0.8809\n",
      "Epoch [7/50], Train Loss: 0.3599, Val Loss: 0.3159, Train Acc: 0.8416, Val Acc: 0.8840\n",
      "Epoch [8/50], Train Loss: 0.3490, Val Loss: 0.3098, Train Acc: 0.8431, Val Acc: 0.8809\n",
      "Epoch [9/50], Train Loss: 0.3297, Val Loss: 0.2971, Train Acc: 0.8502, Val Acc: 0.8683\n",
      "Epoch [10/50], Train Loss: 0.3461, Val Loss: 0.2985, Train Acc: 0.8588, Val Acc: 0.8903\n",
      "Epoch [9/50], Train Loss: 0.3297, Val Loss: 0.2971, Train Acc: 0.8502, Val Acc: 0.8683\n",
      "Epoch [10/50], Train Loss: 0.3461, Val Loss: 0.2985, Train Acc: 0.8588, Val Acc: 0.8903\n",
      "Epoch [11/50], Train Loss: 0.3113, Val Loss: 0.3154, Train Acc: 0.8627, Val Acc: 0.8746\n",
      "Epoch [12/50], Train Loss: 0.3051, Val Loss: 0.2578, Train Acc: 0.8659, Val Acc: 0.9060\n",
      "Epoch [11/50], Train Loss: 0.3113, Val Loss: 0.3154, Train Acc: 0.8627, Val Acc: 0.8746\n",
      "Epoch [12/50], Train Loss: 0.3051, Val Loss: 0.2578, Train Acc: 0.8659, Val Acc: 0.9060\n",
      "Epoch [13/50], Train Loss: 0.3173, Val Loss: 0.2929, Train Acc: 0.8486, Val Acc: 0.8683\n",
      "Epoch [14/50], Train Loss: 0.2921, Val Loss: 0.2735, Train Acc: 0.8627, Val Acc: 0.8809\n",
      "Epoch [13/50], Train Loss: 0.3173, Val Loss: 0.2929, Train Acc: 0.8486, Val Acc: 0.8683\n",
      "Epoch [14/50], Train Loss: 0.2921, Val Loss: 0.2735, Train Acc: 0.8627, Val Acc: 0.8809\n",
      "Epoch [15/50], Train Loss: 0.2826, Val Loss: 0.2466, Train Acc: 0.8706, Val Acc: 0.8997\n",
      "Epoch [16/50], Train Loss: 0.2756, Val Loss: 0.2518, Train Acc: 0.8831, Val Acc: 0.8903\n",
      "Epoch [15/50], Train Loss: 0.2826, Val Loss: 0.2466, Train Acc: 0.8706, Val Acc: 0.8997\n",
      "Epoch [16/50], Train Loss: 0.2756, Val Loss: 0.2518, Train Acc: 0.8831, Val Acc: 0.8903\n",
      "Epoch [17/50], Train Loss: 0.2913, Val Loss: 0.2633, Train Acc: 0.8706, Val Acc: 0.8871\n",
      "Epoch [18/50], Train Loss: 0.2831, Val Loss: 0.2530, Train Acc: 0.8800, Val Acc: 0.8871\n",
      "Epoch [17/50], Train Loss: 0.2913, Val Loss: 0.2633, Train Acc: 0.8706, Val Acc: 0.8871\n",
      "Epoch [18/50], Train Loss: 0.2831, Val Loss: 0.2530, Train Acc: 0.8800, Val Acc: 0.8871\n",
      "Epoch [19/50], Train Loss: 0.2642, Val Loss: 0.2294, Train Acc: 0.8871, Val Acc: 0.8871\n",
      "Epoch [20/50], Train Loss: 0.2522, Val Loss: 0.2270, Train Acc: 0.8886, Val Acc: 0.8934\n",
      "Epoch [19/50], Train Loss: 0.2642, Val Loss: 0.2294, Train Acc: 0.8871, Val Acc: 0.8871\n",
      "Epoch [20/50], Train Loss: 0.2522, Val Loss: 0.2270, Train Acc: 0.8886, Val Acc: 0.8934\n",
      "Epoch [21/50], Train Loss: 0.2381, Val Loss: 0.2575, Train Acc: 0.8949, Val Acc: 0.8746\n",
      "Epoch [22/50], Train Loss: 0.2415, Val Loss: 0.2269, Train Acc: 0.8949, Val Acc: 0.9122\n",
      "Epoch [21/50], Train Loss: 0.2381, Val Loss: 0.2575, Train Acc: 0.8949, Val Acc: 0.8746\n",
      "Epoch [22/50], Train Loss: 0.2415, Val Loss: 0.2269, Train Acc: 0.8949, Val Acc: 0.9122\n",
      "Epoch [23/50], Train Loss: 0.2476, Val Loss: 0.2413, Train Acc: 0.8894, Val Acc: 0.8777\n",
      "Epoch [24/50], Train Loss: 0.2354, Val Loss: 0.2220, Train Acc: 0.8925, Val Acc: 0.9091\n",
      "Epoch [23/50], Train Loss: 0.2476, Val Loss: 0.2413, Train Acc: 0.8894, Val Acc: 0.8777\n",
      "Epoch [24/50], Train Loss: 0.2354, Val Loss: 0.2220, Train Acc: 0.8925, Val Acc: 0.9091\n",
      "Epoch [25/50], Train Loss: 0.2286, Val Loss: 0.2503, Train Acc: 0.9027, Val Acc: 0.8903\n",
      "Epoch [26/50], Train Loss: 0.2331, Val Loss: 0.2319, Train Acc: 0.8965, Val Acc: 0.8934\n",
      "Epoch [25/50], Train Loss: 0.2286, Val Loss: 0.2503, Train Acc: 0.9027, Val Acc: 0.8903\n",
      "Epoch [26/50], Train Loss: 0.2331, Val Loss: 0.2319, Train Acc: 0.8965, Val Acc: 0.8934\n",
      "Epoch [27/50], Train Loss: 0.2475, Val Loss: 0.2516, Train Acc: 0.8918, Val Acc: 0.8809\n",
      "Epoch [28/50], Train Loss: 0.2634, Val Loss: 0.2331, Train Acc: 0.8878, Val Acc: 0.8903\n",
      "Epoch [27/50], Train Loss: 0.2475, Val Loss: 0.2516, Train Acc: 0.8918, Val Acc: 0.8809\n",
      "Epoch [28/50], Train Loss: 0.2634, Val Loss: 0.2331, Train Acc: 0.8878, Val Acc: 0.8903\n",
      "Epoch [29/50], Train Loss: 0.2391, Val Loss: 0.2184, Train Acc: 0.8949, Val Acc: 0.8871\n",
      "Epoch [30/50], Train Loss: 0.2252, Val Loss: 0.2215, Train Acc: 0.9067, Val Acc: 0.9122\n",
      "Epoch [29/50], Train Loss: 0.2391, Val Loss: 0.2184, Train Acc: 0.8949, Val Acc: 0.8871\n",
      "Epoch [30/50], Train Loss: 0.2252, Val Loss: 0.2215, Train Acc: 0.9067, Val Acc: 0.9122\n",
      "Epoch [31/50], Train Loss: 0.2168, Val Loss: 0.2256, Train Acc: 0.9051, Val Acc: 0.8809\n",
      "Epoch [32/50], Train Loss: 0.2077, Val Loss: 0.2134, Train Acc: 0.9098, Val Acc: 0.8997\n",
      "Epoch [31/50], Train Loss: 0.2168, Val Loss: 0.2256, Train Acc: 0.9051, Val Acc: 0.8809\n",
      "Epoch [32/50], Train Loss: 0.2077, Val Loss: 0.2134, Train Acc: 0.9098, Val Acc: 0.8997\n",
      "Epoch [33/50], Train Loss: 0.2066, Val Loss: 0.2133, Train Acc: 0.9161, Val Acc: 0.8966\n",
      "Epoch [34/50], Train Loss: 0.2204, Val Loss: 0.2268, Train Acc: 0.9090, Val Acc: 0.9091\n",
      "Epoch [33/50], Train Loss: 0.2066, Val Loss: 0.2133, Train Acc: 0.9161, Val Acc: 0.8966\n",
      "Epoch [34/50], Train Loss: 0.2204, Val Loss: 0.2268, Train Acc: 0.9090, Val Acc: 0.9091\n",
      "Epoch [35/50], Train Loss: 0.2077, Val Loss: 0.2292, Train Acc: 0.9027, Val Acc: 0.8809\n",
      "Epoch [36/50], Train Loss: 0.2142, Val Loss: 0.2176, Train Acc: 0.9082, Val Acc: 0.8934\n",
      "Epoch [35/50], Train Loss: 0.2077, Val Loss: 0.2292, Train Acc: 0.9027, Val Acc: 0.8809\n",
      "Epoch [36/50], Train Loss: 0.2142, Val Loss: 0.2176, Train Acc: 0.9082, Val Acc: 0.8934\n",
      "Epoch [37/50], Train Loss: 0.1990, Val Loss: 0.2013, Train Acc: 0.9106, Val Acc: 0.9216\n",
      "Epoch [38/50], Train Loss: 0.2018, Val Loss: 0.2112, Train Acc: 0.9208, Val Acc: 0.8934\n",
      "Epoch [37/50], Train Loss: 0.1990, Val Loss: 0.2013, Train Acc: 0.9106, Val Acc: 0.9216\n",
      "Epoch [38/50], Train Loss: 0.2018, Val Loss: 0.2112, Train Acc: 0.9208, Val Acc: 0.8934\n",
      "Epoch [39/50], Train Loss: 0.1921, Val Loss: 0.2241, Train Acc: 0.9200, Val Acc: 0.8871\n",
      "Epoch [40/50], Train Loss: 0.1958, Val Loss: 0.2093, Train Acc: 0.9122, Val Acc: 0.9060\n",
      "Epoch [39/50], Train Loss: 0.1921, Val Loss: 0.2241, Train Acc: 0.9200, Val Acc: 0.8871\n",
      "Epoch [40/50], Train Loss: 0.1958, Val Loss: 0.2093, Train Acc: 0.9122, Val Acc: 0.9060\n",
      "Epoch [41/50], Train Loss: 0.1890, Val Loss: 0.2030, Train Acc: 0.9216, Val Acc: 0.9091\n",
      "Epoch [42/50], Train Loss: 0.1868, Val Loss: 0.2098, Train Acc: 0.9278, Val Acc: 0.8966\n",
      "Epoch [41/50], Train Loss: 0.1890, Val Loss: 0.2030, Train Acc: 0.9216, Val Acc: 0.9091\n",
      "Epoch [42/50], Train Loss: 0.1868, Val Loss: 0.2098, Train Acc: 0.9278, Val Acc: 0.8966\n",
      "Epoch [43/50], Train Loss: 0.1881, Val Loss: 0.2030, Train Acc: 0.9255, Val Acc: 0.9091\n",
      "Epoch [44/50], Train Loss: 0.1842, Val Loss: 0.2062, Train Acc: 0.9153, Val Acc: 0.9028\n",
      "Epoch [43/50], Train Loss: 0.1881, Val Loss: 0.2030, Train Acc: 0.9255, Val Acc: 0.9091\n",
      "Epoch [44/50], Train Loss: 0.1842, Val Loss: 0.2062, Train Acc: 0.9153, Val Acc: 0.9028\n",
      "Epoch [45/50], Train Loss: 0.1941, Val Loss: 0.1986, Train Acc: 0.9161, Val Acc: 0.9122\n",
      "Epoch [46/50], Train Loss: 0.1864, Val Loss: 0.2212, Train Acc: 0.9208, Val Acc: 0.9091\n",
      "Epoch [45/50], Train Loss: 0.1941, Val Loss: 0.1986, Train Acc: 0.9161, Val Acc: 0.9122\n",
      "Epoch [46/50], Train Loss: 0.1864, Val Loss: 0.2212, Train Acc: 0.9208, Val Acc: 0.9091\n",
      "Epoch [47/50], Train Loss: 0.1841, Val Loss: 0.2029, Train Acc: 0.9208, Val Acc: 0.9028\n",
      "Epoch [48/50], Train Loss: 0.1717, Val Loss: 0.2015, Train Acc: 0.9318, Val Acc: 0.9091\n",
      "Epoch [47/50], Train Loss: 0.1841, Val Loss: 0.2029, Train Acc: 0.9208, Val Acc: 0.9028\n",
      "Epoch [48/50], Train Loss: 0.1717, Val Loss: 0.2015, Train Acc: 0.9318, Val Acc: 0.9091\n",
      "Epoch [49/50], Train Loss: 0.1742, Val Loss: 0.2223, Train Acc: 0.9294, Val Acc: 0.8997\n",
      "Epoch [50/50], Train Loss: 0.1655, Val Loss: 0.2187, Train Acc: 0.9325, Val Acc: 0.8934\n",
      "\n",
      "--- 1DCNN_PyTorch Model Evaluation ---\n",
      "Accuracy: 0.9284\n",
      "Precision: 0.9307\n",
      "Recall: 0.9284\n",
      "F1-score: 0.9291\n",
      "Epoch [49/50], Train Loss: 0.1742, Val Loss: 0.2223, Train Acc: 0.9294, Val Acc: 0.8997\n",
      "Epoch [50/50], Train Loss: 0.1655, Val Loss: 0.2187, Train Acc: 0.9325, Val Acc: 0.8934\n",
      "\n",
      "--- 1DCNN_PyTorch Model Evaluation ---\n",
      "Accuracy: 0.9284\n",
      "Precision: 0.9307\n",
      "Recall: 0.9284\n",
      "F1-score: 0.9291\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# One-hot encoding using torch\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train_onehot = np.eye(num_classes)[y_train]\n",
    "y_test_onehot = np.eye(num_classes)[y_test]\n",
    "\n",
    "# Reshape input data for 1D CNN (samples, timesteps, features)\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_cnn, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_cnn, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "full_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32, shuffle=False)\n",
    "\n",
    "# Define 1D CNN Model\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, num_classes, input_length):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=2)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Dynamically determine flatten size\n",
    "        with torch.no_grad():\n",
    "            sample = torch.zeros(1, 1, input_length)\n",
    "            sample = torch.relu(self.conv1(sample))\n",
    "            sample = self.pool(sample)\n",
    "            sample = torch.relu(self.conv2(sample))\n",
    "            sample = self.flatten(sample)\n",
    "            flatten_size = sample.shape[1]\n",
    "        self.fc1 = nn.Linear(flatten_size, 64)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN1D(num_classes, X_train.shape[1]).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10\n",
    "best_val_loss = np.inf\n",
    "counter = 0\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 50\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "          f'Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Prediction on test set\n",
    "model.eval()\n",
    "y_pred_cnn = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred_cnn.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Evaluate model (assuming you have evaluate_model function)\n",
    "cnn_metrics = evaluate_model(y_test, np.array(y_pred_cnn), \"1DCNN_PyTorch\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('PyTorch 1DCNN Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('PyTorch 1DCNN Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Long Short-Term Memory (LSTM) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.3586\n",
      "Epoch 2/20, Loss: 1.1309\n",
      "Epoch 2/20, Loss: 1.1309\n",
      "Epoch 3/20, Loss: 0.8727\n",
      "Epoch 3/20, Loss: 0.8727\n",
      "Epoch 4/20, Loss: 0.7388\n",
      "Epoch 4/20, Loss: 0.7388\n",
      "Epoch 5/20, Loss: 0.6361\n",
      "Epoch 5/20, Loss: 0.6361\n",
      "Epoch 6/20, Loss: 0.5822\n",
      "Epoch 6/20, Loss: 0.5822\n",
      "Epoch 7/20, Loss: 0.5118\n",
      "Epoch 7/20, Loss: 0.5118\n",
      "Epoch 8/20, Loss: 0.4675\n",
      "Epoch 8/20, Loss: 0.4675\n",
      "Epoch 9/20, Loss: 0.4398\n",
      "Epoch 9/20, Loss: 0.4398\n",
      "Epoch 10/20, Loss: 0.3728\n",
      "Epoch 10/20, Loss: 0.3728\n",
      "Epoch 11/20, Loss: 0.3532\n",
      "Epoch 11/20, Loss: 0.3532\n",
      "Epoch 12/20, Loss: 0.3427\n",
      "Epoch 12/20, Loss: 0.3427\n",
      "Epoch 13/20, Loss: 0.3188\n",
      "Epoch 13/20, Loss: 0.3188\n",
      "Epoch 14/20, Loss: 0.3326\n",
      "Epoch 14/20, Loss: 0.3326\n",
      "Epoch 15/20, Loss: 0.2941\n",
      "Epoch 15/20, Loss: 0.2941\n",
      "Epoch 16/20, Loss: 0.3071\n",
      "Epoch 16/20, Loss: 0.3071\n",
      "Epoch 17/20, Loss: 0.2845\n",
      "Epoch 17/20, Loss: 0.2845\n",
      "Epoch 18/20, Loss: 0.2751\n",
      "Epoch 18/20, Loss: 0.2751\n",
      "Epoch 19/20, Loss: 0.2810\n",
      "Epoch 19/20, Loss: 0.2810\n",
      "Epoch 20/20, Loss: 0.2955\n",
      "\n",
      "--- LSTM_PyTorch Model Evaluation ---\n",
      "Accuracy: 0.8640\n",
      "Precision: 0.8706\n",
      "Recall: 0.8640\n",
      "F1-score: 0.8634\n",
      "Epoch 20/20, Loss: 0.2955\n",
      "\n",
      "--- LSTM_PyTorch Model Evaluation ---\n",
      "Accuracy: 0.8640\n",
      "Precision: 0.8706\n",
      "Recall: 0.8640\n",
      "F1-score: 0.8634\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare LSTM input (samples, sequence_length, features)\n",
    "X_train_lstm = torch.tensor(X_train.reshape(X_train.shape[0], X_train.shape[1], 1), dtype=torch.float32).to(device)\n",
    "y_train_lstm = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_test_lstm = torch.tensor(X_test.reshape(X_test.shape[0], X_test.shape[1], 1), dtype=torch.float32).to(device)\n",
    "y_test_lstm = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset_lstm = TensorDataset(X_train_lstm, y_train_lstm)\n",
    "train_loader_lstm = DataLoader(train_dataset_lstm, batch_size=32, shuffle=True)\n",
    "test_dataset_lstm = TensorDataset(X_test_lstm, y_test_lstm)\n",
    "test_loader_lstm = DataLoader(test_dataset_lstm, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define PyTorch LSTM-based classifier\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out)\n",
    "\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = len(label_encoder.classes_)\n",
    "lstm_model = LSTMClassifier(input_size=1, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss, optimizer, and training loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "for epoch in range(20):\n",
    "    lstm_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader_lstm:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/20, Loss: {running_loss/len(train_loader_lstm):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "lstm_model.eval()\n",
    "y_pred_lstm = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader_lstm:\n",
    "        outputs = lstm_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_pred_lstm.extend(preds.cpu().numpy())\n",
    "\n",
    "lstm_metrics = evaluate_model(y_test, y_pred_lstm, \"LSTM_PyTorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison:\n",
      "               accuracy  precision    recall  f1_score\n",
      "Random Forest  0.960526   0.960927  0.960526  0.960632\n",
      "SVM            0.950292   0.951493  0.950292  0.950438\n",
      "1DCNN_PyTorch  0.928363   0.930694  0.928363  0.929054\n",
      "LSTM_PyTorch   0.864035   0.870630  0.864035  0.863355\n",
      "\n",
      "Best performing model by metric:\n",
      "Accuracy: Random Forest (0.9605)\n",
      "Precision: Random Forest (0.9609)\n",
      "Recall: Random Forest (0.9605)\n",
      "F1_score: Random Forest (0.9606)\n",
      "\n",
      "Best performing model by metric:\n",
      "Accuracy: Random Forest (0.9605)\n",
      "Precision: Random Forest (0.9609)\n",
      "Recall: Random Forest (0.9605)\n",
      "F1_score: Random Forest (0.9606)\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison Table\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the results dictionary to a DataFrame for easy comparison\n",
    "comparison_df = pd.DataFrame(model_results).T\n",
    "comparison_df = comparison_df[['accuracy', 'precision', 'recall', 'f1_score']]\n",
    "\n",
    "# Display the model comparison table\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Create a bar plot to visualize the comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "comparison_df.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Model Performance Comparison', fontsize=16)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Metrics', loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a heatmap to visualize the comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(comparison_df, annot=True, cmap='viridis', fmt='.4f', linewidths=0.5)\n",
    "plt.title('Model Performance Comparison Heatmap', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify the best model for each metric\n",
    "best_model = {}\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1_score']:\n",
    "    best_model[metric] = comparison_df[metric].idxmax()\n",
    "    \n",
    "print(\"\\nBest performing model by metric:\")\n",
    "for metric, model in best_model.items():\n",
    "    print(f\"{metric.capitalize()}: {model} ({comparison_df.loc[model, metric]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Normalized for Each Model\n",
    "Below are the normalized confusion matrices for each model, visualized in color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar Bailwal\\AppData\\Local\\Temp\\ipykernel_11596\\2047493655.py:6: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 8))\n"
     ]
    }
   ],
   "source": [
    "# Function to plot normalized confusion matrix\n",
    "def plot_normalized_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]  # Normalize by row (true labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_,\n",
    "                linewidths=0.5, linecolor='white', cbar_kws={'label': ''})\n",
    "    plt.title(f'{model_name} Confusion Matrix (6 PCA Features)', fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices for each model\n",
    "plot_normalized_confusion_matrix(y_test, y_pred_rf, 'Random Forest')\n",
    "plot_normalized_confusion_matrix(y_test, y_pred_svm, 'SVM')\n",
    "plot_normalized_confusion_matrix(y_test, np.array(y_pred_cnn), '1DCNN_PyTorch')\n",
    "plot_normalized_confusion_matrix(y_test, np.array(y_pred_lstm), 'LSTM_PyTorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison with Normalized Confusion Matrices\n",
    "The following section provides a comparison of the models based on their normalized confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison:\n",
      "               accuracy  precision    recall  f1_score\n",
      "Random Forest  0.960526   0.960927  0.960526  0.960632\n",
      "SVM            0.950292   0.951493  0.950292  0.950438\n",
      "1DCNN_PyTorch  0.928363   0.930694  0.928363  0.929054\n",
      "LSTM_PyTorch   0.864035   0.870630  0.864035  0.863355\n",
      "Best performing model by metric:\n",
      "Accuracy: Random Forest (0.9605)\n",
      "Precision: Random Forest (0.9609)\n",
      "Recall: Random Forest (0.9605)\n",
      "F1_score: Random Forest (0.9606)\n",
      "Best performing model by metric:\n",
      "Accuracy: Random Forest (0.9605)\n",
      "Precision: Random Forest (0.9609)\n",
      "Recall: Random Forest (0.9605)\n",
      "F1_score: Random Forest (0.9606)\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison Table\n",
    "comparison_df = pd.DataFrame(model_results).T\n",
    "comparison_df = comparison_df[['accuracy', 'precision', 'recall', 'f1_score']]\n",
    "\n",
    "# Display the model comparison table\n",
    "print('Model Performance Comparison:')\n",
    "print(comparison_df)\n",
    "\n",
    "# Create a bar plot to visualize the comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "comparison_df.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Model Performance Comparison', fontsize=16)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Metrics', loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a heatmap to visualize the comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(comparison_df, annot=True, cmap='viridis', fmt='.4f', linewidths=0.5)\n",
    "plt.title('Model Performance Comparison Heatmap', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify the best model for each metric\n",
    "best_model = {}\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1_score']:\n",
    "    best_model[metric] = comparison_df[metric].idxmax()\n",
    "    \n",
    "print('Best performing model by metric:')\n",
    "for metric, model in best_model.items():\n",
    "    print(f'{metric.capitalize()}: {model} ({comparison_df.loc[model, metric]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train and Test Accuracy Comparison:\n",
      "               Train Accuracy  Test Accuracy\n",
      "Model                                       \n",
      "Random Forest        1.000000       0.960526\n",
      "SVM                  0.952949       0.950292\n",
      "1DCNN_PyTorch        0.952949       0.928363\n",
      "LSTM_PyTorch         0.868883       0.864035\n"
     ]
    }
   ],
   "source": [
    "# Creating bar graphs comparing train and test accuracy for each model\n",
    "def calculate_train_accuracy(model, X_data, y_data):\n",
    "    \"\"\"Calculate training accuracy for traditional ML models\"\"\"\n",
    "    if hasattr(model, 'predict'):\n",
    "        y_pred = model.predict(X_data)\n",
    "        return accuracy_score(y_data, y_pred)\n",
    "    return None\n",
    "\n",
    "# Create lists to store the accuracies\n",
    "models = [\"Random Forest\", \"SVM\", \"1DCNN_PyTorch\", \"LSTM_PyTorch\"]\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "rf_train_acc = calculate_train_accuracy(rf_model, X_train, y_train)\n",
    "rf_test_acc = model_results[\"Random Forest\"][\"accuracy\"]\n",
    "train_accuracies.append(rf_train_acc)\n",
    "test_accuracies.append(rf_test_acc)\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "svm_train_acc = calculate_train_accuracy(svm_model, X_train, y_train)\n",
    "svm_test_acc = model_results[\"SVM\"][\"accuracy\"]\n",
    "train_accuracies.append(svm_train_acc)\n",
    "test_accuracies.append(svm_test_acc)\n",
    "\n",
    "# For 1DCNN, use the training history tracked during model training\n",
    "# The last training accuracy from the history\n",
    "cnn_train_acc = train_accuracies[-1]  # Using the last training accuracy value\n",
    "cnn_test_acc = model_results[\"1DCNN_PyTorch\"][\"accuracy\"]\n",
    "train_accuracies.append(cnn_train_acc)\n",
    "test_accuracies.append(cnn_test_acc)\n",
    "\n",
    "# For LSTM, we need to calculate it manually\n",
    "lstm_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader_lstm:\n",
    "        outputs = lstm_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "lstm_train_acc = correct / total\n",
    "lstm_test_acc = model_results[\"LSTM_PyTorch\"][\"accuracy\"]\n",
    "train_accuracies.append(lstm_train_acc)\n",
    "test_accuracies.append(lstm_test_acc)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "accuracy_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Test Accuracy': test_accuracies\n",
    "})\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.35\n",
    "x = range(len(models))\n",
    "\n",
    "plt.bar([i - bar_width/2 for i in x], accuracy_df['Train Accuracy'], \n",
    "        width=bar_width, label='Train Accuracy', color='skyblue', edgecolor='black')\n",
    "plt.bar([i + bar_width/2 for i in x], accuracy_df['Test Accuracy'], \n",
    "        width=bar_width, label='Test Accuracy', color='lightcoral', edgecolor='black')\n",
    "\n",
    "plt.xlabel('Models', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.title('Train vs Test Accuracy for Different Models', fontsize=16)\n",
    "plt.xticks(x, models, fontsize=12)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add accuracy values on top of bars\n",
    "for i, v in enumerate(accuracy_df['Train Accuracy']):\n",
    "    plt.text(i - bar_width/2, v + 0.02, f'{v:.2f}', ha='center', fontsize=10)\n",
    "    \n",
    "for i, v in enumerate(accuracy_df['Test Accuracy']):\n",
    "    plt.text(i + bar_width/2, v + 0.02, f'{v:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create individual bar graphs for each model\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    \n",
    "    model_data = [accuracy_df.loc[i, 'Train Accuracy'], accuracy_df.loc[i, 'Test Accuracy']]\n",
    "    bars = plt.bar(['Train', 'Test'], model_data, color=['skyblue', 'lightcoral'], edgecolor='black')\n",
    "    \n",
    "    plt.title(f'{model} Accuracy', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add accuracy values on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{height:.4f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy values in a table\n",
    "print(\"Model Train and Test Accuracy Comparison:\")\n",
    "print(accuracy_df.set_index('Model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add confusion matrices for training data\n",
    "def plot_train_confusion_matrix(model, X_train, y_train, model_name):\n",
    "    \"\"\"Plot confusion matrix for training data\"\"\"\n",
    "    if hasattr(model, 'predict'):\n",
    "        # For sklearn models\n",
    "        y_pred_train = model.predict(X_train)\n",
    "    elif model_name == \"1DCNN_PyTorch\":\n",
    "        # For PyTorch CNN model\n",
    "        model.eval()\n",
    "        y_pred_train = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                y_pred_train.extend(predicted.cpu().numpy())\n",
    "        # We need to map these predictions back to the original train indices\n",
    "        # This is an approximation since we're using the training loader\n",
    "        y_pred_train = np.array(y_pred_train)\n",
    "    elif model_name == \"LSTM_PyTorch\":\n",
    "        # For PyTorch LSTM model\n",
    "        model.eval()\n",
    "        y_pred_train = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in train_loader_lstm:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                y_pred_train.extend(predicted.cpu().numpy())\n",
    "        # Similar approximation\n",
    "        y_pred_train = np.array(y_pred_train)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    cm = confusion_matrix(y_train, y_pred_train)\n",
    "    cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_,\n",
    "                linewidths=0.5, linecolor='white', cbar_kws={'label': ''})\n",
    "    plt.title(f'{model_name} Training Confusion Matrix (6 PCA Features)', fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and plot training confusion matrices for each model\n",
    "print(\"Training Confusion Matrices:\")\n",
    "plot_train_confusion_matrix(rf_model, X_train, y_train, \"Random Forest\")\n",
    "plot_train_confusion_matrix(svm_model, X_train, y_train, \"SVM\")\n",
    "plot_train_confusion_matrix(model, X_train_tensor, y_train, \"1DCNN_PyTorch\")\n",
    "plot_train_confusion_matrix(lstm_model, X_train_lstm, y_train_lstm, \"LSTM_PyTorch\")\n",
    "\n",
    "# Individual accuracy visualizations for each model\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Function to create individual accuracy bar plots\n",
    "def plot_individual_accuracy(model_name, train_acc, test_acc, subplot_pos):\n",
    "    plt.subplot(2, 2, subplot_pos)\n",
    "    accuracies = [train_acc, test_acc]\n",
    "    bars = plt.bar(['Train', 'Test'], accuracies, color=['skyblue', 'lightcoral'], width=0.6, edgecolor='black')\n",
    "    \n",
    "    plt.title(f'{model_name} Accuracy', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add accuracy values on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{height:.4f}', ha='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add a horizontal line for perfect accuracy reference\n",
    "    plt.axhline(y=1.0, color='r', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Calculate the difference between train and test accuracy\n",
    "    diff = abs(train_acc - test_acc)\n",
    "    plt.annotate(f'Diff: {diff:.4f}', xy=(0.5, min(train_acc, test_acc) - 0.1),\n",
    "                 ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot individual accuracy charts\n",
    "plot_individual_accuracy(\"Random Forest\", rf_train_acc, rf_test_acc, 1)\n",
    "plot_individual_accuracy(\"SVM\", svm_train_acc, svm_test_acc, 2)\n",
    "plot_individual_accuracy(\"1DCNN\", train_accuracies[-2], test_accuracies[-2], 3)\n",
    "plot_individual_accuracy(\"LSTM\", lstm_train_acc, lstm_test_acc, 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Individual Model Training vs Testing Accuracy', fontsize=20, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Create a comparison table\n",
    "comparison_table = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Test Accuracy': test_accuracies,\n",
    "    'Difference': [abs(t-e) for t, e in zip(train_accuracies, test_accuracies)]\n",
    "})\n",
    "\n",
    "# Sort by test accuracy (highest first)\n",
    "comparison_table = comparison_table.sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "# Display the table with formatting\n",
    "print(\"Model Accuracy Comparison (Sorted by Test Accuracy):\")\n",
    "print(comparison_table.set_index('Model').round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a radar chart for testing accuracy\n",
    "from math import pi\n",
    "\n",
    "# Prepare data for radar chart\n",
    "models = [\"Random Forest\", \"SVM\", \"1DCNN_PyTorch\", \"LSTM_PyTorch\"]\n",
    "test_accuracies = [rf_test_acc, svm_test_acc, cnn_test_acc, lstm_test_acc]\n",
    "\n",
    "# Add the first value to close the radar chart\n",
    "categories = models + [models[0]]\n",
    "values = test_accuracies + [test_accuracies[0]]\n",
    "\n",
    "# Create radar chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Calculate angle for each category\n",
    "angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]\n",
    "\n",
    "# Plot data\n",
    "ax.plot(angles, values, linewidth=2, linestyle='solid', label='Test Accuracy')\n",
    "ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "# Add labels for each category\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(models, fontsize=12)\n",
    "\n",
    "# Set range for radial axis\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10)\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Testing Accuracy Radar Chart', fontsize=16, pad=20)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "\n",
    "# Add labels for each value on the radar chart\n",
    "for i, value in enumerate(values[:-1]):  # Exclude the last value (duplicate for closing the chart)\n",
    "    angle = angles[i]\n",
    "    ax.text(angle, value + 0.05, f'{value:.2f}', ha='center', fontsize=10, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
